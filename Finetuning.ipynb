{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "distilled SBERT-fine-tune.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClqewEEEh8Hd"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6_fHm2vmcyq"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w32QtfcQh_sg",
        "outputId": "f8ccff2f-3fb3-4d33-d886-b89ea213a2f9"
      },
      "source": [
        "# Использовать gpu\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QZtTAhbiC0x"
      },
      "source": [
        "!pip install transformers\n",
        "!apt-get install unzip wget -y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W98yFjQ3iJmd"
      },
      "source": [
        "PATH_TO_DISK = '/content/drive'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRjNOmM6iDZL",
        "outputId": "72334556-8c26-414a-cd4e-3d2cf9adb232"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(PATH_TO_DISK)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQFAlEAMkg3c"
      },
      "source": [
        "## Download pretrained model and pretrained tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97EEW0KGk-UC"
      },
      "source": [
        "PATH_TO_MODEL = os.path.join(PATH_TO_DISK, 'My Drive', 'Colab Notebooks/15_epoch_simple_lstm_100.pt')\n",
        "\n",
        "PATH_TO_PRETRAINED_TOKENIZER = 'sberbank-ai/sbert_large_nlu_ru'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zAdGmwbqBN-"
      },
      "source": [
        "# Загрузить sbertTokenizer\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "sbertTokenizer = AutoTokenizer.from_pretrained(PATH_TO_PRETRAINED_TOKENIZER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UH0zU9FMkmoD"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Класс дистиллированной модели-ученика, которую мы будем файнтюнить.\n",
        "# Нужно скопировать из тетрадки, в которой модель дистиллировалась\n",
        "class SimpleLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers,\n",
        "                 bidirectional, dropout, batch_size, device=None):\n",
        "        super(SimpleLSTM, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "\n",
        "        self.rnn = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional,\n",
        "                           dropout=dropout)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.device = self.init_device(device)\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    @staticmethod\n",
        "    def init_device(device):\n",
        "        if device is None:\n",
        "            return torch.device('cuda')\n",
        "        return device\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (Variable(torch.zeros(2 * self.n_layers, self.batch_size, self.hidden_dim).to(self.device)),\n",
        "                Variable(torch.zeros(2 * self.n_layers, self.batch_size, self.hidden_dim).to(self.device)))\n",
        "\n",
        "    def forward(self, text, text_lengths=None):\n",
        "        self.hidden = self.init_hidden()\n",
        "        x = self.embedding(text)\n",
        "        x, self.hidden = self.rnn(x, self.hidden)\n",
        "        hidden, cell = self.hidden\n",
        "        hidden = self.dropout(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n",
        "        x = self.fc(hidden)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMmOvpibb9Kx"
      },
      "source": [
        "# Загружаем дистиллированную модель. Все параметры должны быть перенесены из тетрадки с дистилляцией.\n",
        "modelParameters = {'input_dim' : sbertTokenizer.vocab_size,\n",
        "                   'embedding_dim' : 50,\n",
        "                   'hidden_dim' : 256,\n",
        "                   'output_dim' : 1024,\n",
        "                   'n_layers' : 2,\n",
        "                   'bidirectional' : True,\n",
        "                   'dropout' : 0.2,\n",
        "                   'batch_size' : 32}\n",
        "\n",
        "model = SimpleLSTM(\n",
        "            input_dim = modelParameters['input_dim'],\n",
        "            embedding_dim = modelParameters['embedding_dim'],\n",
        "            hidden_dim = modelParameters['hidden_dim'],\n",
        "            output_dim = modelParameters['output_dim'],\n",
        "            n_layers = modelParameters['n_layers'],\n",
        "            bidirectional = modelParameters['bidirectional'],\n",
        "            dropout = modelParameters['dropout'],\n",
        "            batch_size = modelParameters['batch_size'])\n",
        "\n",
        "model.load_state_dict(torch.load(PATH_TO_MODEL))\n",
        "\n",
        "# Переносим модель на GPU\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDz1sPxbcDXX",
        "outputId": "b07bf961-14d9-4e22-c0aa-afaea8e061ff"
      },
      "source": [
        "# Проверим, что модель правильно загрузилась\n",
        "tokenized_sent = sbertTokenizer(['Инфляция - жуткая штука'] *32 , padding=True, truncation=True, max_length=20)\n",
        "inds = torch.tensor(tokenized_sent['input_ids'])\n",
        "inds_cuda = inds.to(device)\n",
        "model.eval()\n",
        "model(inds_cuda.t(), None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.9378, -0.1869, -0.5879,  ...,  0.1863,  0.5791,  0.5997],\n",
              "        [ 0.9378, -0.1869, -0.5879,  ...,  0.1863,  0.5791,  0.5997],\n",
              "        [ 0.9378, -0.1869, -0.5879,  ...,  0.1863,  0.5791,  0.5997],\n",
              "        ...,\n",
              "        [ 0.9378, -0.1869, -0.5879,  ...,  0.1863,  0.5791,  0.5997],\n",
              "        [ 0.9378, -0.1869, -0.5879,  ...,  0.1863,  0.5791,  0.5997],\n",
              "        [ 0.9378, -0.1869, -0.5879,  ...,  0.1863,  0.5791,  0.5997]],\n",
              "       device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4L7o03DHWjzE"
      },
      "source": [
        "# Prepare data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3Ur99khiRAC"
      },
      "source": [
        "# Путь к файлу с данными в .csv формате.\n",
        "# Здесь мы используем датасет Lenta.ru\n",
        "PATH_TO_DATA = os.path.join(PATH_TO_DISK, 'My Drive', 'Colab Notebooks/test-lenta.csv')\n",
        "\n",
        "# Если данные в .zip файле, предварительно их нужно распаковать и указать путь на распакованный .csv-файл\n",
        "# !unzip -o PATH_TO_DATA\n",
        "# PATH_TO_DATA = ...\n",
        "\n",
        "TOKENIZER_MAX_LENGHT = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0nrDS8pm8IK"
      },
      "source": [
        "def getPreparedDataFromCSV(path, max_lenght):\n",
        "    '''\n",
        "    Принимает:  path - путь к .csv файлу с данными\n",
        "                max_lenght - параметр для токенизатора\n",
        "    Выдает:     input_ids - токенизированные предложения, torch.tensor\n",
        "                labels - класссы каждого предложения, которые мы должны научиться предсказывать, torch.tensor\n",
        "                id_to_topic - соответствие классов и реальных меток, list\n",
        "    '''\n",
        "    data = pd.read_csv(path)\n",
        "\n",
        "    topic_to_id = {}\n",
        "    id_to_topic = []\n",
        "    for topic in data.topic:\n",
        "        if not topic in topic_to_id:\n",
        "            topic_to_id[topic] = len(id_to_topic)\n",
        "            id_to_topic.append(topic)\n",
        "\n",
        "    labels = []\n",
        "    for topic in data.topic:\n",
        "        labels.append(topic_to_id[topic])\n",
        "    \n",
        "    input_ids = [] # encoded sentences\n",
        "\n",
        "    for sent in data.title:\n",
        "        encoded_input = sbertTokenizer(sent, padding='max_length',\n",
        "                                       truncation=True,\n",
        "                                       max_length=max_lenght,\n",
        "                                       return_tensors='pt')\n",
        "        input_ids.append(encoded_input['input_ids'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    return input_ids, labels, id_to_topic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5NyQViWANnj",
        "outputId": "92c59b6f-a907-4b35-b3f1-ba1312768e43"
      },
      "source": [
        "# Прочитаем данные из файла и рандомно разобьем их на датасеты\n",
        "# в отношении 7 : 2 : 1 для train : validation : test\n",
        "\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "input_ids, labels, id_to_topic = getPreparedDataFromCSV(PATH_TO_DATA, TOKENIZER_MAX_LENGHT)\n",
        "dataset = TensorDataset(input_ids, labels)\n",
        "\n",
        "\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.2 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))\n",
        "print('{:>5,} testing samples'.format(test_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35,000 training samples\n",
            "10,000 validation samples\n",
            "5,000 testing samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkk3y_z_Fsep"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hyc8ho17gdNv"
      },
      "source": [
        "trainingParameters = {\n",
        "    'optimizer' : {\n",
        "        'lr' : 2e-5,\n",
        "        'eps' : 1e-8\n",
        "    },\n",
        "    'epochs' : 50,\n",
        "    'batch_size' : modelParameters['batch_size']\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oFeaUsBuXh3"
      },
      "source": [
        "# Создадим DataLoader для каждого датасета\n",
        "\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = trainingParameters['batch_size']\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset,\n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "testing_dataloader = DataLoader(\n",
        "            test_dataset,\n",
        "            sampler = SequentialSampler(test_dataset),\n",
        "            batch_size = batch_size\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBILkBfKGLBe"
      },
      "source": [
        "from transformers import AdamW\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = trainingParameters['optimizer']['lr'],\n",
        "                  eps = trainingParameters['optimizer']['eps']\n",
        "                )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tz1Pej3HwYZ"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = trainingParameters['epochs']\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r3Ja7qzIJLn"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwFf7BgJLnIA"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgqnctvOmgyC"
      },
      "source": [
        "# Инициализируем модель, которую будем тренировать\n",
        "# Здесь можно поиграть с количеством слоев и внутренних параметров\n",
        "# Я пробовала один линейный слой и число внутренних параметров (512, 512), (1024, 512), (512, 128)\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.model = model\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        self.lin1 = nn.Linear(1024, 512)\n",
        "        self.lin2 = nn.Linear(512, 256)\n",
        "        self.lin3 = nn.Linear(256, len(id_to_topic))\n",
        "\n",
        "    def forward(self, x, text_lengths=None):\n",
        "        x = self.model(x.t(), text_lengths=text_lengths).squeeze(1)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = self.lin3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gD3iBnkOq14k",
        "outputId": "5a2bdcf3-5ceb-48ff-b0ea-ece08d9a9310"
      },
      "source": [
        "net = Net()\n",
        "net.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (model): SimpleLSTM(\n",
              "    (embedding): Embedding(120138, 50)\n",
              "    (rnn): LSTM(50, 256, num_layers=2, dropout=0.2, bidirectional=True)\n",
              "    (fc): Linear(in_features=512, out_features=1024, bias=True)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (lin1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (lin2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (lin3): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syqaDKOELyKa",
        "outputId": "acfabd88-c8a0-421e-fcc5-41d6bfbe0f5a"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# We'll store validation loss, validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "total_t0 = time.time()\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    print()\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    net.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        if len(batch[0]) != batch_size:\n",
        "            continue\n",
        "\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].cuda()\n",
        "        b_labels = batch[1].cuda()\n",
        "\n",
        "        net.zero_grad()\n",
        "        optimizer.zero_grad()  \n",
        "\n",
        "        result = net(b_input_ids)\n",
        "\n",
        "        loss = criterion(result, b_labels)\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        del b_input_ids\n",
        "        del b_labels\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "    # Validation\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        if len(batch[0]) != batch_size:\n",
        "            continue\n",
        "    \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[1].to(device)\n",
        "\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            result = net(b_input_ids)\n",
        "\n",
        "        loss = criterion(result, b_labels)\n",
        "            \n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        _, predicted = torch.max(result.data, 1)\n",
        "        total += b_labels.size(0)\n",
        "        correct += (predicted == b_labels).sum().item()\n",
        "\n",
        "        del b_input_ids\n",
        "        del b_labels\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "\n",
        "\n",
        "    avg_val_accuracy = correct / total\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:13.\n",
            "\n",
            "  Average training loss: 2.26\n",
            "  Training epcoh took: 0:00:13\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.32\n",
            "  Validation Loss: 2.14\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:00.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:13.\n",
            "\n",
            "  Average training loss: 2.01\n",
            "  Training epcoh took: 0:00:13\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.48\n",
            "  Validation Loss: 1.79\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:00.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:13.\n",
            "\n",
            "  Average training loss: 1.69\n",
            "  Training epcoh took: 0:00:13\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.52\n",
            "  Validation Loss: 1.53\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:00.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:13.\n",
            "\n",
            "  Average training loss: 1.51\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.54\n",
            "  Validation Loss: 1.42\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 5 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:00.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:13.\n",
            "\n",
            "  Average training loss: 1.40\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.57\n",
            "  Validation Loss: 1.34\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 6 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:00.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:13.\n",
            "\n",
            "  Average training loss: 1.33\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.58\n",
            "  Validation Loss: 1.30\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 7 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:00.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:13.\n",
            "\n",
            "  Average training loss: 1.28\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.59\n",
            "  Validation Loss: 1.27\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 8 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 1.23\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.60\n",
            "  Validation Loss: 1.24\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 9 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:00.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 1.20\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.60\n",
            "  Validation Loss: 1.22\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 10 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 1.17\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 1.20\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 11 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 1.14\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 1.19\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 12 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 1.12\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.62\n",
            "  Validation Loss: 1.17\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 13 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 1.09\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.62\n",
            "  Validation Loss: 1.16\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 14 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 1.08\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.62\n",
            "  Validation Loss: 1.15\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 15 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 1.05\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.63\n",
            "  Validation Loss: 1.14\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 16 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 1.03\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.63\n",
            "  Validation Loss: 1.13\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 17 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 1.01\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.63\n",
            "  Validation Loss: 1.13\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 18 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 1.00\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.64\n",
            "  Validation Loss: 1.12\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 19 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.99\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.64\n",
            "  Validation Loss: 1.12\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 20 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.98\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.64\n",
            "  Validation Loss: 1.11\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 21 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.97\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.64\n",
            "  Validation Loss: 1.11\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 22 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.95\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.64\n",
            "  Validation Loss: 1.10\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 23 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.94\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.65\n",
            "  Validation Loss: 1.10\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 24 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.93\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.65\n",
            "  Validation Loss: 1.10\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 25 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.93\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.65\n",
            "  Validation Loss: 1.09\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 26 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.91\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.65\n",
            "  Validation Loss: 1.09\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 27 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.91\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.65\n",
            "  Validation Loss: 1.09\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 28 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.90\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.65\n",
            "  Validation Loss: 1.08\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 29 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.89\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.65\n",
            "  Validation Loss: 1.09\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 30 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.88\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.65\n",
            "  Validation Loss: 1.08\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 31 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.87\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.65\n",
            "  Validation Loss: 1.08\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 32 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.87\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.65\n",
            "  Validation Loss: 1.08\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 33 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.86\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.66\n",
            "  Validation Loss: 1.08\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 34 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.85\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.66\n",
            "  Validation Loss: 1.08\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 35 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.85\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.66\n",
            "  Validation Loss: 1.08\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 36 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.85\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.66\n",
            "  Validation Loss: 1.08\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 37 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.84\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.66\n",
            "  Validation Loss: 1.07\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 38 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.84\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.66\n",
            "  Validation Loss: 1.07\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 39 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.83\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.66\n",
            "  Validation Loss: 1.07\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 40 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.83\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.66\n",
            "  Validation Loss: 1.07\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 41 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.82\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.66\n",
            "  Validation Loss: 1.07\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 42 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.82\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.66\n",
            "  Validation Loss: 1.07\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 43 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.82\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.66\n",
            "  Validation Loss: 1.07\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 44 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.81\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.66\n",
            "  Validation Loss: 1.07\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 45 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.81\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.66\n",
            "  Validation Loss: 1.07\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 46 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.81\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.66\n",
            "  Validation Loss: 1.07\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 47 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.81\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.66\n",
            "  Validation Loss: 1.07\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 48 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.81\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.66\n",
            "  Validation Loss: 1.07\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 49 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.81\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.66\n",
            "  Validation Loss: 1.07\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 50 / 50 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:01.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:00:03.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:00:04.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:00:05.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:00:06.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:00:08.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:00:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:00:10.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:00:11.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:00:13.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:00:14.\n",
            "\n",
            "  Average training loss: 0.81\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.66\n",
            "  Validation Loss: 1.07\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:12:13 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2mr9A_Gb1qz"
      },
      "source": [
        "## Display statictics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m8qFEazDNFXv",
        "outputId": "13c6b1ee-339c-4a3e-e35a-321bb1288ecd"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.set_option('precision', 2)\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "df = df_stats.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.26</td>\n",
              "      <td>2.14</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0:00:13</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.01</td>\n",
              "      <td>1.79</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0:00:13</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.69</td>\n",
              "      <td>1.53</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0:00:13</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.51</td>\n",
              "      <td>1.42</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.40</td>\n",
              "      <td>1.34</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.33</td>\n",
              "      <td>1.30</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.28</td>\n",
              "      <td>1.27</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.23</td>\n",
              "      <td>1.24</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.20</td>\n",
              "      <td>1.22</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.17</td>\n",
              "      <td>1.20</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.14</td>\n",
              "      <td>1.19</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.12</td>\n",
              "      <td>1.17</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.09</td>\n",
              "      <td>1.16</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.08</td>\n",
              "      <td>1.15</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1.05</td>\n",
              "      <td>1.14</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.03</td>\n",
              "      <td>1.13</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.01</td>\n",
              "      <td>1.13</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.99</td>\n",
              "      <td>1.12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.98</td>\n",
              "      <td>1.11</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.97</td>\n",
              "      <td>1.11</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.95</td>\n",
              "      <td>1.10</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.94</td>\n",
              "      <td>1.10</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.93</td>\n",
              "      <td>1.10</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.93</td>\n",
              "      <td>1.09</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.91</td>\n",
              "      <td>1.09</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.91</td>\n",
              "      <td>1.09</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.90</td>\n",
              "      <td>1.08</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.89</td>\n",
              "      <td>1.09</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.88</td>\n",
              "      <td>1.08</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.87</td>\n",
              "      <td>1.08</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.87</td>\n",
              "      <td>1.08</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.86</td>\n",
              "      <td>1.08</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.85</td>\n",
              "      <td>1.08</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.85</td>\n",
              "      <td>1.08</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.85</td>\n",
              "      <td>1.08</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.84</td>\n",
              "      <td>1.07</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.84</td>\n",
              "      <td>1.07</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.83</td>\n",
              "      <td>1.07</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.83</td>\n",
              "      <td>1.07</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.82</td>\n",
              "      <td>1.07</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.82</td>\n",
              "      <td>1.07</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.82</td>\n",
              "      <td>1.07</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.81</td>\n",
              "      <td>1.07</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.81</td>\n",
              "      <td>1.07</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.81</td>\n",
              "      <td>1.07</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.81</td>\n",
              "      <td>1.07</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.81</td>\n",
              "      <td>1.07</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.81</td>\n",
              "      <td>1.07</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>0.81</td>\n",
              "      <td>1.07</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:00:14</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               2.26         2.14           0.32       0:00:13         0:00:01\n",
              "2               2.01         1.79           0.48       0:00:13         0:00:01\n",
              "3               1.69         1.53           0.52       0:00:13         0:00:01\n",
              "4               1.51         1.42           0.54       0:00:14         0:00:01\n",
              "5               1.40         1.34           0.57       0:00:14         0:00:01\n",
              "6               1.33         1.30           0.58       0:00:14         0:00:01\n",
              "7               1.28         1.27           0.59       0:00:14         0:00:01\n",
              "8               1.23         1.24           0.60       0:00:14         0:00:01\n",
              "9               1.20         1.22           0.60       0:00:14         0:00:01\n",
              "10              1.17         1.20           0.61       0:00:14         0:00:01\n",
              "11              1.14         1.19           0.61       0:00:14         0:00:01\n",
              "12              1.12         1.17           0.62       0:00:14         0:00:01\n",
              "13              1.09         1.16           0.62       0:00:14         0:00:01\n",
              "14              1.08         1.15           0.62       0:00:14         0:00:01\n",
              "15              1.05         1.14           0.63       0:00:14         0:00:01\n",
              "16              1.03         1.13           0.63       0:00:14         0:00:01\n",
              "17              1.01         1.13           0.63       0:00:14         0:00:01\n",
              "18              1.00         1.12           0.64       0:00:14         0:00:01\n",
              "19              0.99         1.12           0.64       0:00:14         0:00:01\n",
              "20              0.98         1.11           0.64       0:00:14         0:00:01\n",
              "21              0.97         1.11           0.64       0:00:14         0:00:01\n",
              "22              0.95         1.10           0.64       0:00:14         0:00:01\n",
              "23              0.94         1.10           0.65       0:00:14         0:00:01\n",
              "24              0.93         1.10           0.65       0:00:14         0:00:01\n",
              "25              0.93         1.09           0.65       0:00:14         0:00:01\n",
              "26              0.91         1.09           0.65       0:00:14         0:00:01\n",
              "27              0.91         1.09           0.65       0:00:14         0:00:01\n",
              "28              0.90         1.08           0.65       0:00:14         0:00:01\n",
              "29              0.89         1.09           0.65       0:00:14         0:00:01\n",
              "30              0.88         1.08           0.65       0:00:14         0:00:01\n",
              "31              0.87         1.08           0.65       0:00:14         0:00:01\n",
              "32              0.87         1.08           0.65       0:00:14         0:00:01\n",
              "33              0.86         1.08           0.66       0:00:14         0:00:01\n",
              "34              0.85         1.08           0.66       0:00:14         0:00:01\n",
              "35              0.85         1.08           0.66       0:00:14         0:00:01\n",
              "36              0.85         1.08           0.66       0:00:14         0:00:01\n",
              "37              0.84         1.07           0.66       0:00:14         0:00:01\n",
              "38              0.84         1.07           0.66       0:00:14         0:00:01\n",
              "39              0.83         1.07           0.66       0:00:14         0:00:01\n",
              "40              0.83         1.07           0.66       0:00:14         0:00:01\n",
              "41              0.82         1.07           0.66       0:00:14         0:00:01\n",
              "42              0.82         1.07           0.66       0:00:14         0:00:01\n",
              "43              0.82         1.07           0.66       0:00:14         0:00:01\n",
              "44              0.81         1.07           0.66       0:00:14         0:00:01\n",
              "45              0.81         1.07           0.66       0:00:14         0:00:01\n",
              "46              0.81         1.07           0.66       0:00:14         0:00:01\n",
              "47              0.81         1.07           0.66       0:00:14         0:00:01\n",
              "48              0.81         1.07           0.66       0:00:14         0:00:01\n",
              "49              0.81         1.07           0.66       0:00:14         0:00:01\n",
              "50              0.81         1.07           0.66       0:00:14         0:00:01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CutE55T6L4gr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "f51b359b-0f7a-48e1-a492-af60ba95fa02"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNZ1BkfrK7PZ"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDZlNbOKNeFd",
        "outputId": "c79d3c60-dc33-47c0-bee2-55a949713a88"
      },
      "source": [
        "net.eval()\n",
        "\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "print()\n",
        "print('Testing...')\n",
        "\n",
        "for (step, batch) in enumerate(testing_dataloader):\n",
        "\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    if len(batch[0]) != batch_size:\n",
        "            continue\n",
        "    \n",
        "    if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(testing_dataloader)))\n",
        "\n",
        "    b_input_ids, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        result = net(b_input_ids)\n",
        "\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    _, predicted = torch.max(result.data, 1)\n",
        "\n",
        "    predictions.append(predicted)\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "    del b_input_ids\n",
        "    del b_labels\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print('DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Testing...\n",
            "  Batch    40  of    157.\n",
            "  Batch    80  of    157.\n",
            "  Batch   120  of    157.\n",
            "DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDb2mTW3Ufm3",
        "outputId": "d961d7f7-c6c7-40c5-8e9d-85adcbe8011b"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "predicted_labels = np.concatenate([np.array(prediction.to('cpu'), dtype='long') for prediction in predictions])\n",
        "\n",
        "y_true = np.concatenate(true_labels).flatten()\n",
        "y_pred = predicted_labels.flatten()\n",
        "\n",
        "print(\"Precision: {0:.4f}\".format(precision_score(y_true, y_pred, average='macro'))) # unweighted average of precisions\n",
        "print(\"Recall: {0:.4f}\".format(recall_score(y_true, y_pred, average='macro'))) # unweighted average of recalls\n",
        "print(\"F1-score: {0:.4f}\".format(f1_score(y_true, y_pred, average='macro'))) # unweighted average of f1-scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.6661\n",
            "Recall: 0.6649\n",
            "F1-score: 0.6650\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugSLY13qWJ55"
      },
      "source": [
        "# Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltf0COQohwRW"
      },
      "source": [
        "OUTPUT_DIR = './model_save_18_05'\n",
        "MODEL_NAME_TO_SAVE = '15_100_50ep'\n",
        "PARAMETERS_NAME_TO_SAVE = 'args-15_100_50ep.bin'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5X4DxhvNRcfb",
        "outputId": "4045a488-4f52-42cd-fa12-1b6d180bd466"
      },
      "source": [
        "output_dir = './model_save'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save model, tokenizer and training arguments\n",
        "torch.save(net.state_dict(), os.path.join(output_dir, MODEL_NAME_TO_SAVE))\n",
        "sbertTokenizer.save_pretrained(output_dir)\n",
        "torch.save(trainingParameters, os.path.join(output_dir, PARAMETERS_NAME_TO_SAVE))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqNekoZXbvQU"
      },
      "source": [
        "Look at the sizes, out of curiousity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY8TekbTWsbn",
        "outputId": "0398b73c-1809-45be-8054-17c745ee2918"
      },
      "source": [
        "!ls -l --block-size=K ./model_save/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 41164K\n",
            "-rw-r--r-- 1 root root 36719K May 18 17:06 15_100_50ep\n",
            "-rw-r--r-- 1 root root     1K May 18 17:06 args-15_100_50ep.bin\n",
            "-rw-r--r-- 1 root root     1K May 18 17:06 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root     1K May 18 17:06 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root  2689K May 18 17:06 tokenizer.json\n",
            "-rw-r--r-- 1 root root  1739K May 18 17:06 vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiCvO-UgWgO9"
      },
      "source": [
        "Save to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YrXQIqpWfTG"
      },
      "source": [
        "# Copy the model files to a directory in your Google Drive.\n",
        "!cp -r ./model_save/ OUTPUT_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-I1RKpGXGZT"
      },
      "source": [
        "To load model from drive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiYeAnC5SbSE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "307396fe-6fab-4fe7-ec59-73f984b337cf"
      },
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "# Net class must be the same as class of the saved model. Initialize it somewehere before\n",
        "model = Net()\n",
        "\n",
        "model.load_state_dict(torch.load(os.path.join(output_dir, MODEL_NAME_TO_SAVE)))\n",
        "tokenizer = BertTokenizerFast.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (model): SimpleLSTM(\n",
              "    (embedding): Embedding(120138, 50)\n",
              "    (rnn): LSTM(50, 256, num_layers=2, dropout=0.2, bidirectional=True)\n",
              "    (fc): Linear(in_features=512, out_features=1024, bias=True)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (lin1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (lin2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (lin3): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uySI4JHSewxO"
      },
      "source": [
        "Немного потестируем, что все загрузилось"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvvwNmzVdX0q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "b50b769f-a05a-421b-e878-18d08cbd7f9f"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "testSent = 'В стране инфляция'\n",
        "\n",
        "input = tokenizer(testSent, padding='max_length', truncation=True, max_length=20, return_tensors='pt')\n",
        "input_ind = input['input_ids']\n",
        "\n",
        "gpu_input_ind = input_ind.to(device)\n",
        "\n",
        "_ , predicted = torch.max(model(gpu_input_ind), 1)\n",
        "id_to_topic[predicted]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-4b3f9099a1dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mgpu_input_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_input_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mid_to_topic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-a1600a408e47>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, text_lengths)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_lengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_lengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-a53faa520e9a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text, text_lengths)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n\u001b[0;32m--> 607\u001b[0;31m                                'Expected hidden[0] size {}, got {}')\n\u001b[0m\u001b[1;32m    608\u001b[0m         self.check_hidden_size(hidden[1], self.get_expected_cell_size(input, batch_sizes),\n\u001b[1;32m    609\u001b[0m                                'Expected hidden[1] size {}, got {}')\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    221\u001b[0m                           msg: str = 'Expected hidden size {}, got {}') -> None:\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden[0] size (4, 1, 256), got [4, 32, 256]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8c3T1gFcwSS"
      },
      "source": [
        "Done :)"
      ]
    }
  ]
}